using System;
using System.Collections.Generic;
using System.IO;
using Android.App;
using Android.Content;
using Android.Content.Res;
using Android.Graphics;
using Android.Hardware.Camera2;
using Android.Hardware.Camera2.Params;
using Android.Media;
using Android.OS;
using Android.Support.V8.Renderscript;
using Android.Runtime;
using Android.Util;
using Android.Views;
using Com.Twinfog.Camera;
using Java.IO;
using Java.Lang;
using Java.Nio;
using Java.Util;
using Java.Util.Concurrent;
using RType = Android.Support.V8.Renderscript.Type;
using ACameraPreviewProcessor = Com.Twinfog.Camera.CameraPreviewProcessor;

namespace FaceDetection.Droid
{
  public class CameraWrapper //: Java.Lang.Object // , ImageReader.IOnImageAvailableListener
  {
    // Max preview width that is guaranteed by Camera2 API
    const int MAX_PREVIEW_WIDTH = 1920;

    // Max preview height that is guaranteed by Camera2 API
    const int MAX_PREVIEW_HEIGHT = 1080;

    Activity activity;

    public CameraWrapper(Activity activity)
    {
      this.activity = activity;
    }

    CameraManager cameraManager;
    string cameraId;
    ImageReader imageReader;
    CameraDevice cameraDevice;

    // A {@link Semaphore} to prevent the app from exiting before closing the camera.
    Semaphore cameraOpenCloseLock = new Semaphore(1);

    // A {@link CameraCaptureSession } for camera preview.
    CameraCaptureSession captureSession;

    //{@link CaptureRequest.Builder} for the camera preview
    CaptureRequest.Builder previewRequestBuilder;

    // {@link CaptureRequest} generated by {@link #mPreviewRequestBuilder}
    CaptureRequest previewRequest;

    Size previewSize;

    CameraDeviceStateCallbackListener cameraStateListener;

    CameraCaptureSessionCallbackListener captureSessionListener;

    CameraCaptureListener captureListener;

    bool flashSupported;

    public Size OpenCamera(Size previewSize = null)
    {
      cameraManager = (CameraManager)activity.GetSystemService(Context.CameraService);

      for (var i = 0; i < cameraManager.GetCameraIdList().Length; i++)
      {
        var camId = cameraManager.GetCameraIdList()[i];
        CameraCharacteristics characteristics = cameraManager.GetCameraCharacteristics(camId);

        //var fpsRange = Cast<Range>(characteristics.Get(CameraCharacteristics.ControlAeAvailableTargetFpsRanges));

        //var r = fpsRange as Android.Util.Range;

        // We don't use a front facing camera in this sample.
        var facing = (Integer)characteristics.Get(CameraCharacteristics.LensFacing);
        if (facing != null && facing == (Integer.ValueOf((int)LensFacing.Front))) { continue; }

        var map = (StreamConfigurationMap)characteristics.Get(CameraCharacteristics.ScalerStreamConfigurationMap);
        if (map == null) { continue; }

         if (previewSize == null)
        {
          // For still image captures, we use the largest available size.

          var sizes = Arrays.AsList(map.GetOutputSizes((int)ImageFormatType.Yuv420888));
          Size largest = null;
          var comparer = new CompareSizesByArea();
          foreach (Size size in sizes)
          {
            

            if ((largest == null || comparer.Compare(largest, size) < 0) && size.Width <= MAX_PREVIEW_WIDTH && size.Height <= MAX_PREVIEW_HEIGHT)
            {
              largest = size;
            }
          }
          //Size largest = (Size)Collections.Max(sizes, new CompareSizesByArea());
          previewSize = largest;
        }
        this.previewSize = previewSize;

        imageReader = ImageReader.NewInstance(previewSize.Width, previewSize.Height, ImageFormatType.Yuv420888, /*maxImages*/5);

        var ncpus = Java.Lang.Runtime.GetRuntime().AvailableProcessors();

        var camPreviewProcessor = new ACameraPreviewProcessor(activity, ncpus);
        camPreviewProcessor.Rgb += CamPreviewProcessor_Rgb;

        //camPreviewProcessor. PreviewFrameAvailable += CamPreviewProcessor_PreviewFrameAvailable;
        imageReader.SetOnImageAvailableListener(camPreviewProcessor, backgroundHandler);


        // Find out if we need to swap dimension to get the preview size relative to sensor
        // coordinate.
        var displayRotation = activity.WindowManager.DefaultDisplay.Rotation;
        //noinspection ConstantConditions
        var sensorOrientation = (int)characteristics.Get(CameraCharacteristics.SensorOrientation);
        bool swappedDimensions = false;
        switch (displayRotation)
        {
          case SurfaceOrientation.Rotation0:
          case SurfaceOrientation.Rotation180:
            if (sensorOrientation == 90 || sensorOrientation == 270)
            {
              swappedDimensions = true;
            }
            break;
          case SurfaceOrientation.Rotation90:
          case SurfaceOrientation.Rotation270:
            if (sensorOrientation == 0 || sensorOrientation == 180)
            {
              swappedDimensions = true;
            }
            break;
          default:
            System.Diagnostics.Debug.WriteLine($"{nameof(CameraWrapper)} :: {nameof(OpenCamera)} :: Display rotation is invalid: {displayRotation}");
            break;
        }

        Point displaySize = new Point();
        activity.WindowManager.DefaultDisplay.GetSize(displaySize);
        var rotatedPreviewWidth = previewSize.Width;
        var rotatedPreviewHeight = previewSize.Height;
        var maxPreviewWidth = displaySize.X;
        var maxPreviewHeight = displaySize.Y;

        if (swappedDimensions)
        {
          rotatedPreviewWidth = previewSize.Height;
          rotatedPreviewHeight = previewSize.Width;
          maxPreviewWidth = displaySize.Y;
          maxPreviewHeight = displaySize.X;
        }

        if (maxPreviewWidth > MAX_PREVIEW_WIDTH)
        {
          maxPreviewWidth = MAX_PREVIEW_WIDTH;
        }

        if (maxPreviewHeight > MAX_PREVIEW_HEIGHT)
        {
          maxPreviewHeight = MAX_PREVIEW_HEIGHT;
        }

        // Danger, W.R.! Attempting to use too large a preview size could  exceed the camera
        // bus' bandwidth limitation, resulting in gorgeous previews but the storage of
        // garbage capture data.
        previewSize = ChooseOptimalSize(map.GetOutputSizes(Class.FromType(typeof(SurfaceTexture))),
            rotatedPreviewWidth, rotatedPreviewHeight, maxPreviewWidth, maxPreviewHeight, previewSize);

        // We fit the aspect ratio of TextureView to the size of preview we picked.
        var orientation = activity.Resources.Configuration.Orientation;
        //if (orientation == Android.Content.Res.Orientation.Landscape)
        //{
        //  mTextureView.SetAspectRatio(mPreviewSize.Width, mPreviewSize.Height);
        //}
        //else
        //{
        //  mTextureView.SetAspectRatio(mPreviewSize.Height, mPreviewSize.Width);
        //}

        // Check if the flash is supported.
        var available = (Java.Lang.Boolean)characteristics.Get(CameraCharacteristics.FlashInfoAvailable);

        if (available == null) { flashSupported = false; }
        else { flashSupported = (bool)available; }


        cameraId = camId;
        break;
      }
      try
      {
        if (!cameraOpenCloseLock.TryAcquire(2500, TimeUnit.Microseconds))
        {
          throw new System.Exception("Time out waiting to lock camera opening.");
        }

        if (cameraStateListener == null)
        {
          cameraStateListener = new CameraDeviceStateCallbackListener(cameraManager);
          cameraStateListener.Opened += OnOpened;
          cameraStateListener.Disconnected += OnDisconnected;
          cameraStateListener.Error += OnError;
        }
        cameraManager.OpenCamera(cameraId, cameraStateListener, backgroundHandler);
      }
      catch (CameraAccessException e)
      {
        e.PrintStackTrace();
      }
      catch (InterruptedException e)
      {
        throw new System.Exception("Interrupted while trying to lock camera opening.", e);
      }

      return previewSize;
    }

    public void CloseCamera()
    {
      try
      {
        cameraOpenCloseLock.Acquire();
        if (null != captureSession)
        {
          captureSession.Close();
          captureSession = null;
        }
        if (null != cameraDevice)
        {
          cameraDevice.Close();
          cameraDevice = null;
        }
        if (null != imageReader)
        {
          imageReader.Close();
          imageReader = null;
        }
      }
      catch (InterruptedException e)
      {
        throw new RuntimeException("Interrupted while trying to lock camera closing.", e);
      }
      finally
      {
        cameraOpenCloseLock.Release();
      }
    }

    void OnOpened(object sender, CameraDeviceEventArgs e)
    {
      cameraOpenCloseLock.Release();
      cameraDevice = e.Camera;

      try
      {
        //SurfaceTexture texture = mTextureView.SurfaceTexture;
        //SurfaceTexture texture = new SurfaceTexture();
        //if (texture == null)
        //{
        //  throw new IllegalStateException("texture is null");
        //}

        //// We configure the size of default buffer to be the size of camera preview we want.
        //texture.SetDefaultBufferSize(mPreviewSize.Width, mPreviewSize.Height);
        //texture.SetDefaultBufferSize(previewSize.Width, previewSize.Height);
        //texture.FrameAvailable += (sender2, e2) =>
        //{
        //  e2.SurfaceTexture.
        //};

        ////// This is the output Surface we need to start preview.
        //Surface surface = new Surface(texture);

        // We set up a CaptureRequest.Builder with the output Surface.
        previewRequestBuilder = cameraDevice.CreateCaptureRequest(CameraTemplate.Preview);
        previewRequestBuilder.AddTarget(imageReader.Surface);
        //

        // Here, we create a CameraCaptureSession for camera preview.
        var surfaces = new List<Surface>();
        surfaces.Add(imageReader.Surface);

        if (captureSessionListener != null)
        {
          captureSessionListener.Configured -= OnConfigured;
          captureSessionListener.ConfigureFailed -= OnConfigureFailed;
        }
        captureSessionListener = new CameraCaptureSessionCallbackListener(cameraDevice);
        captureSessionListener.Configured += OnConfigured;
        captureSessionListener.ConfigureFailed += OnConfigureFailed;
        cameraDevice.CreateCaptureSession(surfaces, captureSessionListener, null);
      }
      catch (CameraAccessException ex)
      {
        ex.PrintStackTrace();
      }
    }

    void OnDisconnected(object sender, CameraDeviceEventArgs e)
    {
      cameraOpenCloseLock.Release();
      e.Camera.Close();
      cameraDevice = null;
    }

    void OnError(object sender, CameraDeviceEventArgs e)
    {
      System.Diagnostics.Debug.WriteLine($"{nameof(CameraWrapper)} :: {nameof(OnError)} :: Camera Error: {e.Error}");

      cameraOpenCloseLock.Release();
      e.Camera.Close();
      cameraDevice = null;

      if (activity != null) { activity.Finish(); }
    }

    void OnConfigured(object sender, CameraCaptureSessionEventArgs e)
    {
      // The camera is already closed
      if (null == cameraDevice)
      {
        return;
      }

      // When the session is ready, we start displaying the preview.
      captureSession = e.Session;
      try
      {
        // Auto focus should be continuous for camera preview.
        previewRequestBuilder.Set(CaptureRequest.ControlAfMode, (int)ControlAFMode.Edof);
        // Flash is automatically enabled when necessary. For now, we skip this.
        // SetAutoFlash(previewRequestBuilder);

        // Finally, we start displaying the camera preview.
        previewRequest = previewRequestBuilder.Build();

        if (captureListener == null)
        {
          captureListener = new CameraCaptureListener();
          captureListener.CaptureCompleted += OnCaptureCompleted;
          captureListener.CaptureProgressed += OnCaptureProgressed;
        }
        captureSession.SetRepeatingRequest(previewRequest, captureListener, backgroundHandler);
      }
      catch (CameraAccessException ex)
      {
        ex.PrintStackTrace();
      }
    }

    void OnConfigureFailed(object sender, CameraCaptureSessionEventArgs e)
    {
      System.Diagnostics.Debug.WriteLine($"{nameof(CameraWrapper)} :: {nameof(OnConfigureFailed)} :: Camera Configuration Failed.");
    }

    void OnCaptureCompleted(object sender, CameraCaptureEventArgs e)
    {
      // TODO
    }

    void OnCaptureProgressed(object sender, CameraCaptureEventArgs e)
    {
      // TODO
    }

    #region Listener and Callback Implementations - CameraDevice.StateCallback, CameraCaptureSession.StateCallback, CameraCaptureSession.CaptureCallback

    class CameraDeviceEventArgs : EventArgs
    {
      public CameraDevice Camera { get; set; }
      public CameraError Error { get; set; }
    }

    class CameraDeviceStateCallbackListener : CameraDevice.StateCallback
    {
      public event EventHandler<CameraDeviceEventArgs> Opened;
      public event EventHandler<CameraDeviceEventArgs> Disconnected;
      public event EventHandler<CameraDeviceEventArgs> Error;

      CameraManager cameraManager;

      public CameraDeviceStateCallbackListener(CameraManager cameraManager)
      {
        this.cameraManager = cameraManager;
      }

      public override void OnDisconnected(CameraDevice camera)
      {
        var handler = Disconnected;
        if (handler != null) { handler(cameraManager, new CameraDeviceEventArgs { Camera = camera }); }
      }

      public override void OnError(CameraDevice camera, [GeneratedEnum] CameraError error)
      {
        var handler = Error;
        if (handler != null) { handler(cameraManager, new CameraDeviceEventArgs { Camera = camera, Error = error }); }
      }

      public override void OnOpened(CameraDevice camera)
      {
        var handler = Opened;
        if (handler != null) { handler(cameraManager, new CameraDeviceEventArgs { Camera = camera }); }
      }
    }

    class CameraCaptureSessionEventArgs : EventArgs
    {
      public CameraCaptureSession Session { get; set; }
    }

    class CameraCaptureSessionCallbackListener : CameraCaptureSession.StateCallback
    {
      public event EventHandler<CameraCaptureSessionEventArgs> Configured;
      public event EventHandler<CameraCaptureSessionEventArgs> ConfigureFailed;

      CameraDevice cameraDevice;

      public CameraCaptureSessionCallbackListener(CameraDevice cameraDevice)
      {
        this.cameraDevice = cameraDevice;
      }

      public override void OnConfigured(CameraCaptureSession session)
      {
        var handler = Configured;
        if (handler != null) { handler(cameraDevice, new CameraCaptureSessionEventArgs { Session = session }); }
      }

      public override void OnConfigureFailed(CameraCaptureSession session)
      {
        var handler = ConfigureFailed;
        if (handler != null) { handler(cameraDevice, new CameraCaptureSessionEventArgs { Session = session }); }
      }
    }

    class CameraCaptureEventArgs : EventArgs
    {
      public CaptureRequest Request { get; set; }
      public CaptureResult Result { get; set; }
    }

    class CameraCaptureListener : CameraCaptureSession.CaptureCallback
    {
      public event EventHandler<CameraCaptureEventArgs> CaptureCompleted;
      public event EventHandler<CameraCaptureEventArgs> CaptureProgressed;

      public override void OnCaptureCompleted(CameraCaptureSession session, CaptureRequest request, TotalCaptureResult result)
      {
        var handler = CaptureCompleted;
        if (handler != null)
        {
          handler(session, new CameraCaptureEventArgs { Request = request, Result = result });
        }
      }

      public override void OnCaptureProgressed(CameraCaptureSession session, CaptureRequest request, CaptureResult partialResult)
      {
        var handler = CaptureProgressed;
        if (handler != null)
        {
          handler(session, new CameraCaptureEventArgs { Request = request, Result = partialResult });
        }
      }
    }

    #endregion

    #region Background Thread (Looper)
    HandlerThread backgroundThread;
    Handler backgroundHandler;

    /// <summary>
    /// Starts a background thread and its {@link Handler}.
    /// </summary>
    public void StartBackgroundThread()
    {
      if (backgroundThread == null)
      {
        backgroundThread = new HandlerThread("CameraBackground");
        backgroundThread.Start();
        backgroundHandler = new Handler(backgroundThread.Looper);
      }
    }

    /// <summary>
    /// Stops the background thread and its {@link Handler}.
    /// </summary>
    public void StopBackgroundThread()
    {
      if (backgroundThread != null)
      {
        backgroundThread.QuitSafely();
        try
        {
          backgroundThread.Join();
          backgroundThread = null;
          backgroundHandler = null;
        }
        catch (InterruptedException e)
        {
          e.PrintStackTrace();
        }
      }
    }
    #endregion

    #region ImageReader.IOnImageAvailableListener implementation


    public event EventHandler<CameraPreviewEventArgs> PreviewFrameAvailable;

    void CamPreviewProcessor_PreviewFrameAvailable(object sender, CameraPreviewEventArgs e)
    {
      var handler = PreviewFrameAvailable;
      if (handler != null) { handler(this, e); }
    }

    public void OnImageAvailable(ImageReader reader)
    {
      var handler = PreviewFrameAvailable;
      if (handler == null) { return; }

      //handler(this, null);
      using (var image = reader.AcquireNextImage())
      {
        try
        {
          //var plane = reader.AcquireNextImage().GetPlanes()[0];
          if (image == null) { return; }

          //var planes = image.GetPlanes();
          //var plane = planes[0];
          //var buffer = plane.Buffer;

          //buffer.Rewind();
          //byte[] bytes = new byte[buffer.Remaining()];
          //buffer.Get(bytes);

          ////using (var output = new FileOutputStream(new Java.IO.File(activity.GetExternalFilesDir(null), "florin-pic.jpg")))
          ////{
          ////  try
          ////  {
          ////    output.Write(bytes);
          ////  }
          ////  catch (Java.IO.IOException e)
          ////  {
          ////    System.Diagnostics.Debug.WriteLine($"{e}");
          ////  }
          ////}

          //using (Bitmap bitmap = BitmapFactory.DecodeByteArray(bytes, 0, bytes.Length))
          //{
          //  var rawBuffer = ByteBuffer.Allocate(bitmap.ByteCount);
          //  bitmap.CopyPixelsToBuffer(rawBuffer);
          //  rawBuffer.Rewind();
          //  byte[] rawBytes = new byte[rawBuffer.Remaining()];
          //  rawBuffer.Get(rawBytes);

          //  handler(this, new CameraPreviewEventArgs { FrameData = rawBytes, Width = bitmap.Width, Height = bitmap.Height });
          //}

          using (Bitmap bitmap = YUV_420_888_toRGB(image, image.Width, image.Height))
          {
              var rawBuffer = ByteBuffer.Allocate(bitmap.ByteCount);
              bitmap.CopyPixelsToBuffer(rawBuffer);
              rawBuffer.Rewind();
              byte[] rawBytes = new byte[rawBuffer.Remaining()];
              rawBuffer.Get(rawBytes);

              handler(this, new CameraPreviewEventArgs { FrameData = rawBytes, Width = bitmap.Width, Height = bitmap.Height });
          }
        }
        finally
        {
          image?.Close();
        }
      }
    }

    private Bitmap YUV_420_888_toRGB(Image image, int width, int height)
    {
      // Get the three image planes
      Image.Plane[] planes = image.GetPlanes();
      ByteBuffer buffer = planes[0].Buffer;
      byte[] y = new byte[buffer.Remaining()];
      buffer.Get(y);

      buffer = planes[1].Buffer;
      byte[] u = new byte[buffer.Remaining()];
      buffer.Get(u);

      buffer = planes[2].Buffer;
      byte[] v = new byte[buffer.Remaining()];
      buffer.Get(v);

      // get the relevant RowStrides and PixelStrides
      // (we know from documentation that PixelStride is 1 for y)
      int yRowStride = planes[0].RowStride;
      int uvRowStride = planes[1].RowStride;  // we know from   documentation that RowStride is the same for u and v.
      int uvPixelStride = planes[1].PixelStride;  // we know from   documentation that PixelStride is the same for u and v.


      // rs creation just for demo. Create rs just once in onCreate and use it again.
      RenderScript rs = (activity as MainActivity).RenderScript; // RenderScript.create(this);
      //RenderScript rs = RenderScript.Create(Android.App.Application.Context);
      //RenderScript rs = MainActivity.rs;
      ScriptC_yuv420888 mYuv420 = new ScriptC_yuv420888(rs);

      // Y,U,V are defined as global allocations, the out-Allocation is the Bitmap.
      // Note also that uAlloc and vAlloc are 1-dimensional while yAlloc is 2-dimensional.
      RType.Builder typeUcharY = new RType.Builder(rs, Element.U8(rs));
      typeUcharY.SetX(yRowStride).SetY(height);
      Allocation yAlloc = Allocation.CreateTyped(rs, typeUcharY.Create());
      yAlloc.CopyFrom(y);
      mYuv420.Set_ypsIn(yAlloc);

      RType.Builder typeUcharUV = new RType.Builder(rs, Element.U8(rs));
      // note that the size of the u's and v's are as follows:
      //      (  (width/2)*PixelStride + padding  ) * (height/2)
      // =    (RowStride                          ) * (height/2)
      // but I noted that on the S7 it is 1 less...
      typeUcharUV.SetX(u.Length);
      Allocation uAlloc = Allocation.CreateTyped(rs, typeUcharUV.Create());
      uAlloc.CopyFrom(u);
      mYuv420.Set_uIn(uAlloc);

      Allocation vAlloc = Allocation.CreateTyped(rs, typeUcharUV.Create());
      vAlloc.CopyFrom(v);
      mYuv420.Set_vIn(vAlloc);

      // handover parameters
      mYuv420.Set_picWidth(width);
      mYuv420.Set_uvRowStride(uvRowStride);
      mYuv420.Set_uvPixelStride(uvPixelStride);

      Bitmap outBitmap = Bitmap.CreateBitmap(width, height, Bitmap.Config.Argb8888);
      Allocation outAlloc = Allocation.CreateFromBitmap(rs, outBitmap, Allocation.MipmapControl.MipmapNone, Allocation.UsageScript);

      Script.LaunchOptions lo = new Script.LaunchOptions();
      lo.SetX(0, width);  // by this we ignore the y’s padding zone, i.e. the right side of x between width and yRowStride
      lo.SetY(0, height);

      mYuv420.ForEach_doConvert(outAlloc, lo);
      outAlloc.CopyTo(outBitmap);

      return outBitmap;
    }

    const int DEFAULT_PIXEL_STRIDE = 2; // bytes per sample 
    const int BYTES_PER_RGB_PIX = 3; // byts per pixel 

    /**
     * Generate a direct RGB {@link ByteBuffer} from a YUV420_888 {@link Image}. 
     */
    static ByteBuffer ConvertToRGB(Image yuvImage)
    {
      // TODO: Optimize this with renderscript intrinsic. 
      int width = yuvImage.Width;
      int height = yuvImage.Height;
      ByteBuffer buf = ByteBuffer.AllocateDirect(BYTES_PER_RGB_PIX * width * height);

      Image.Plane yPlane = yuvImage.GetPlanes()[0];
      Image.Plane uPlane = yuvImage.GetPlanes()[1];
      Image.Plane vPlane = yuvImage.GetPlanes()[2];

      ByteBuffer yBuf = yPlane.Buffer;
      ByteBuffer uBuf = uPlane.Buffer;
      ByteBuffer vBuf = vPlane.Buffer;

      yBuf.Rewind();
      uBuf.Rewind();
      vBuf.Rewind();

      int yRowStride = yPlane.RowStride;
      int vRowStride = vPlane.RowStride;
      int uRowStride = uPlane.RowStride;

      int yPixStride = yPlane.PixelStride;
      int vPixStride = vPlane.PixelStride;
      int uPixStride = uPlane.PixelStride;

      byte[] yuvPixel = { 0, 0, 0 };
      byte[] yFullRow = new byte[yPixStride * (width - 1) + 1];
      byte[] uFullRow = new byte[uPixStride * (width / 2 - 1) + 1];
      byte[] vFullRow = new byte[vPixStride * (width / 2 - 1) + 1];
      byte[] finalRow = new byte[BYTES_PER_RGB_PIX * width];
      for (int i = 0; i < height; i++)
      {
        int halfH = i / 2;
        yBuf.Position(yRowStride * i);
        yBuf.Get(yFullRow);
        uBuf.Position(uRowStride * halfH);
        uBuf.Get(uFullRow);
        vBuf.Position(vRowStride * halfH);
        vBuf.Get(vFullRow);
        for (int j = 0; j < width; j++)
        {
          int halfW = j / 2;
          yuvPixel[0] = yFullRow[yPixStride * j];
          yuvPixel[1] = uFullRow[uPixStride * halfW];
          yuvPixel[2] = vFullRow[vPixStride * halfW];
          YuvToRgb(yuvPixel, j * BYTES_PER_RGB_PIX, /*out*/finalRow);
        }
        buf.Put(finalRow);
      }

      yBuf.Rewind();
      uBuf.Rewind();
      vBuf.Rewind();
      buf.Rewind();
      return buf;
    }

    /**
     * Convert a single YUV pixel to RGB. 
     */
    static void YuvToRgb(byte[] yuvData, int outOffset, /*out*/byte[] rgbOut)
    {
      const int COLOR_MAX = 255;

      float y = yuvData[0] & 0xFF;  // Y channel 
      float cb = yuvData[1] & 0xFF; // U channel 
      float cr = yuvData[2] & 0xFF; // V channel 

      // convert YUV -> RGB (from JFIF's "Conversion to and from RGB" section) 
      float r = y + 1.402f * (cr - 128);
      float g = y - 0.34414f * (cb - 128) - 0.71414f * (cr - 128);
      float b = y + 1.772f * (cb - 128);

      // clamp to [0,255] 
      rgbOut[outOffset] = (byte)System.Math.Max(0, System.Math.Min(COLOR_MAX, r));
      rgbOut[outOffset + 1] = (byte)System.Math.Max(0, System.Math.Min(COLOR_MAX, g));
      rgbOut[outOffset + 2] = (byte)System.Math.Max(0, System.Math.Min(COLOR_MAX, b));
    }

    void CamPreviewProcessor_Rgb(object sender, RgbAvailableEventArgs e)
    {
      var handler = PreviewFrameAvailable;
      if (handler != null)
      {
        handler(this, new CameraPreviewEventArgs { FrameData = e.P0, Width = e.P1, Height = e.P2, FrameOrder = e.P3 });
      }
    }

    #endregion

    static Size ChooseOptimalSize(Size[] choices, int textureViewWidth,
        int textureViewHeight, int maxWidth, int maxHeight, Size aspectRatio)
    {
      // Collect the supported resolutions that are at least as big as the preview Surface
      var bigEnough = new List<Size>();
      // Collect the supported resolutions that are smaller than the preview Surface
      var notBigEnough = new List<Size>();
      int w = aspectRatio.Width;
      int h = aspectRatio.Height;

      for (var i = 0; i < choices.Length; i++)
      {
        Size option = choices[i];
        if ((option.Width <= maxWidth) && (option.Height <= maxHeight) &&
               option.Height == option.Width * h / w)
        {
          if (option.Width >= textureViewWidth &&
              option.Height >= textureViewHeight)
          {
            bigEnough.Add(option);
          }
          else
          {
            notBigEnough.Add(option);
          }
        }
      }

      // Pick the smallest of those big enough. If there is no one big enough, pick the
      // largest of those not big enough.
      if (bigEnough.Count > 0)
      {
        return (Size)Collections.Min(bigEnough, new CompareSizesByArea());
      }
      else if (notBigEnough.Count > 0)
      {
        return (Size)Collections.Max(notBigEnough, new CompareSizesByArea());
      }
      else
      {
        System.Diagnostics.Debug.WriteLine($"{nameof(CameraWrapper)} :: {nameof(ChooseOptimalSize)} :: Couldn't find find any suitable preview size");
        return choices[0];
      }
    }

    public static T Cast<T>(Java.Lang.Object obj) where T : class
    {
      var propertyInfo = obj.GetType().GetProperty("Instance");
      return propertyInfo == null ? null : propertyInfo.GetValue(obj, null) as T;
    }
  }
}
